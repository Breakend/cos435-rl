There are many different excellent resources for reinforcement learning. To name a few:

\begin{itemize}
  \item \textbf{Reinforcement Learning: An Introduction} by Richard S. Sutton and Andrew G. Barto.
  \item \textbf{Reinforcement Learning: Bit by Bit} by Xiuyuan Lu, Benjamin Van Roy, Vikranth Dwaracherla, Morteza Ibrahimi, Ian Osband, and Zheng Wen.
  \item \textbf{Bandit Algorithms} by Tor Lattimore and Csaba Szepesvári (if you're interested in bandits).
  \item \textbf{Algorithms for Reinforcement Learning} by Csaba Szepesvári.
  \item \textbf{Mathematical Foundations of Reinforcement Learning} by Shiyu Zhao.
\end{itemize}

Now, there remains the question of why create a new set of notes on the matter? To my mind, each of these resources covers a distinct view of reinforcement learning. The Sutton and Barto view doesn't quite capture the Lu et al. view, for example. And all of them are geared toward a world where we spend significant time on tabular methods. We don't live in that world anymore. The future is function approximation with deep neural networks. And reinforcement learning, to my mind, is a path toward artificial general intelligence.\footnote{Here I mean ``general'' in the sense of \emph{learning and adaptation}: an agent's ability to achieve goals across any tractable environment by efficiently acquiring and using experience, rather than being preloaded with solutions to many fixed tasks.} Others might disagree with me, but this book is my attempt to ramp up someone in one semester, from scratch, to engage with the frontiers of reinforcement learning research, with an emphasis on areas that I think will be important in the next decade.

\paragraph{Acknowledgements.}
Much of these notes draw inspiration from lecture notes and course materials by Ben Eysenbach, Ben Van Roy, Emma Brunskill, Doina Precup, and David Silver. I am grateful to them for making their excellent teaching resources available to the community.
